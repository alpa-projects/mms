Type	BS	#Microbatch	#GPU	Mean Time(s)	Std Time(s)	#Params (Billion)	TFLOPs	Peak Mem (GB)
gpt_inference	1	1	32	0.151	0.001	2.649B	5.23	0.555
gpt_inference	4	1	32	0.426	0	2.649B	7.4	1.107
gpt_inference	16	1	32	1.746	0.002	2.649B	7.22	3.51
gpt_inference	1	1	16	0.144	0.001	2.649B	5.47	0.742
gpt_inference	4	1	16	0.378	0	2.649B	8.35	1.107
gpt_inference	16	1	16	1.533	0.003	2.649B	8.22	3.51
gpt_inference	1	1	8	0.142	0	2.649B	5.56	1.035
gpt_inference	4	1	8	0.364	0.002	2.649B	8.65	1.392
gpt_inference	16	1	8	1.454	0.001	2.649B	8.67	3.51
gpt_inference	1	1	4	0.142	0	2.649B	11.07	1.621
gpt_inference	4	1	4	0.36	0	2.649B	17.49	1.978
gpt_inference	16	1	4	1.433	0.004	2.649B	17.59	3.655
gpt_inference	1	1	2	0.144	0	2.649B	21.95	2.794
gpt_inference	4	1	2	0.362	0.002	2.649B	34.79	3.15
gpt_inference	16	1	2	1.443	0.001	2.649B	34.94	4.827
gpt_inference	1	1	1	0.145	0	2.649B	43.54	5.378
gpt_inference	4	1	1	0.366	0.001	2.649B	68.85	5.72
gpt_inference	16	1	1	1.455	0.013	2.649B	69.29	7.34
gpt_inference	1	1	32	0.248	0	6.654B	7.59	0.954
gpt_inference	4	1	32	0.797	0.001	6.654B	9.43	1.517
gpt_inference	16	1	32	3.24	0.016	6.654B	9.28	3.769
gpt_inference	1	1	16	0.236	0.001	6.654B	7.98	1.356
gpt_inference	4	1	16	0.715	0.002	6.654B	10.51	1.739
gpt_inference	16	1	16	2.959	0.003	6.654B	10.16	3.703
gpt_inference	1	1	8	0.232	0	6.654B	8.1	2.106
gpt_inference	4	1	8	0.705	0.001	6.654B	10.66	2.489
gpt_inference	16	1	8	2.842	0.004	6.654B	10.58	4.271
gpt_inference	1	1	4	0.23	0	6.654B	16.31	3.606
gpt_inference	4	1	4	0.699	0.004	6.654B	21.5	3.989
gpt_inference	16	1	4	2.818	0.002	6.654B	21.34	5.772
gpt_inference	1	1	2	0.232	0	6.654B	32.42	6.607
gpt_inference	4	1	2	0.698	0.001	6.654B	43.07	6.99
gpt_inference	16	1	2	2.839	0.002	6.654B	42.36	8.772
gpt_inference	1	1	1	0.236	0	6.654B	63.61	12.992
gpt_inference	4	1	1	0.698	0.001	6.654B	86.2	13.352
gpt_inference	16	1	1	-1	0	6.654B	-1	0
gpt_inference	1	1	32	-1	0	15.364B	-1	0
gpt_inference	4	1	32	-1	0	15.364B	-1	0
gpt_inference	16	1	32	-1	0	15.364B	-1	0
gpt_inference	1	1	16	0.461	0.003	15.364B	9.11	2.515
gpt_inference	4	1	16	1.516	0.002	15.364B	11.07	2.994
gpt_inference	16	1	16	6.36	0.007	15.364B	10.56	5.222
gpt_inference	1	1	8	0.454	0	15.364B	9.24	4.273
gpt_inference	4	1	8	1.491	0.007	15.364B	11.26	4.752
gpt_inference	16	1	8	6.281	0.001	15.364B	10.69	6.98
gpt_inference	1	1	4	0.451	0	15.364B	18.6	7.79
gpt_inference	4	1	4	1.498	0.001	15.364B	22.4	8.268
gpt_inference	16	1	4	6.271	0.017	15.364B	21.41	10.496